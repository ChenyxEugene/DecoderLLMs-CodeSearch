{"pair_id": 401, "source": "CSN Train", "query": "Return the python representation of the document", "code": "def as_python(self, infile, include_original_shex: bool=False):\n        \"\"\" Return the python representation of the document \"\"\"\n        self._context.resolve_circular_references()            # add forwards for any circular entries\n        body = ''\n        for k in self._context.ordered_elements():\n            v = self._context.grammarelts[k]\n            if isinstance(v, (JSGLexerRuleBlock, JSGObjectExpr)):\n                body += v.as_python(k)\n                if isinstance(v, JSGObjectExpr) and not self._context.has_typeid:\n                    self._context.directives.append(f'_CONTEXT.TYPE_EXCEPTIONS.append(\"{k}\")')\n            elif isinstance(v, JSGForwardRef):\n                pass\n            elif isinstance(v, (JSGValueType, JSGArrayExpr)):\n                body += f\"\\n\\n\\n{k} = {v.signature_type()}\"\n            else:\n                raise NotImplementedError(\"Unknown grammar elt for {}\".format(k))\n            self._context.forward_refs.pop(k, None)\n\n        body = '\\n' + '\\n'.join(self._context.directives) + body\n        return _jsg_python_template.format(infile=infile,\n                                           original_shex='# ' + self.text if include_original_shex else \"\",\n                                           version=__version__,\n                                           gendate=datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\"),\n                                           body=body)", "dist_before": 0.5018671154975891, "dist_after": 0.07784552127122879, "dist_change": -0.4240216016769409}
{"pair_id": 390, "source": "CSN Train", "query": "Remove an already accepted record from the community.\n\n        :param record: Record object.\n        :type record: `invenio_records.api.Record`", "code": "def remove_record(self, record):\n        \"\"\"Remove an already accepted record from the community.\n\n        :param record: Record object.\n        :type record: `invenio_records.api.Record`\n        \"\"\"\n        if not self.has_record(record):\n            current_app.logger.warning(\n                'Community removal: record {uuid} was not in community '\n                '\"{comm}\"'.format(uuid=record.id, comm=self.id))\n        else:\n            key = current_app.config['COMMUNITIES_RECORD_KEY']\n            record[key] = [c for c in record[key] if c != self.id]\n\n        if current_app.config['COMMUNITIES_OAI_ENABLED']:\n            if self.oaiset.has_record(record):\n                self.oaiset.remove_record(record)", "dist_before": 0.11155543476343155, "dist_after": 0.013558316975831985, "dist_change": -0.09799711406230927}
{"pair_id": 385, "source": "CSN Train", "query": "Remove an amendment\n        Given a amendment_id, branch and optionally an\n        author, remove an amendment on the given branch\n        and attribute the commit to author.\n        Returns the SHA of the commit on branch.", "code": "def remove_amendment(self, first_arg, sec_arg, third_arg, fourth_arg=None, commit_msg=None):\n        \"\"\"Remove an amendment\n        Given a amendment_id, branch and optionally an\n        author, remove an amendment on the given branch\n        and attribute the commit to author.\n        Returns the SHA of the commit on branch.\n        \"\"\"\n        if fourth_arg is None:\n            amendment_id, branch_name, author = first_arg, sec_arg, third_arg\n            gh_user = branch_name.split('_amendment_')[0]\n            parent_sha = self.get_master_sha()\n        else:\n            gh_user, amendment_id, parent_sha, author = first_arg, sec_arg, third_arg, fourth_arg\n        if commit_msg is None:\n            commit_msg = \"Delete Amendment '%s' via OpenTree API\" % amendment_id\n        return self._remove_document(gh_user, amendment_id, parent_sha, author, commit_msg)", "dist_before": 0.12166579812765121, "dist_after": 0.023226357996463776, "dist_change": -0.09843944013118744}
{"pair_id": 55, "source": "CSN Train", "query": "Parse argument options.", "code": "def parse_options(metadata):\n    \"\"\"Parse argument options.\"\"\"\n    parser = argparse.ArgumentParser(description='%(prog)s usage:',\n                                     prog=__prog__)\n    setoption(parser, metadata=metadata)\n    return parser", "dist_before": 0.27568700909614563, "dist_after": 0.17907769978046417, "dist_change": -0.09660930931568146}
{"pair_id": 75, "source": "CSN Train", "query": "If a default language has been set, and is still available in\n        `self.available_languages`, return it and remove it from the list.\n\n        If not, simply pop the first available language.", "code": "def _get_default_language(self):\n        \"\"\"\n        If a default language has been set, and is still available in\n        `self.available_languages`, return it and remove it from the list.\n\n        If not, simply pop the first available language.\n        \"\"\"\n\n        assert hasattr(self, 'available_languages'), \\\n            'No available languages have been generated.'\n        assert len(self.available_languages) > 0, \\\n            'No available languages to select from.'\n\n        if (\n            settings.DEFAULT_LANGUAGE and\n            settings.DEFAULT_LANGUAGE in self.available_languages\n        ) or (\n            'language_code' not in self.form.base_fields\n        ):\n            # Default language still available\n\n            self.available_languages.remove(settings.DEFAULT_LANGUAGE)\n            return settings.DEFAULT_LANGUAGE\n\n        else:\n            # Select the first item and return it\n            return self.available_languages.pop(0)", "dist_before": 0.07011096179485321, "dist_after": 0.01953691989183426, "dist_change": -0.05057404190301895}
{"pair_id": 1767, "source": "CSN Test", "query": "Returns Python `callable` which indicates fitting procedure has converged.\n\n  Writing old, new `model_coefficients` as `w0`, `w1`, this function\n  defines convergence as,\n\n  ```python\n  relative_euclidean_norm = (tf.norm(w0 - w1, ord=2, axis=-1) /\n                             (1. + tf.norm(w0, ord=2, axis=-1)))\n  reduce_all(relative_euclidean_norm < tolerance)\n  ```\n\n  where `tf.norm(x, ord=2)` denotes the [Euclidean norm](\n  https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm) of `x`.\n\n  Args:\n    tolerance: `float`-like `Tensor` indicating convergence, i.e., when\n      max relative Euclidean norm weights difference < tolerance`.\n      Default value: `1e-5`.\n    norm_order: Order of the norm. Default value: `2` (i.e., \"Euclidean norm\".)\n\n  Returns:\n    convergence_criteria_fn: Python `callable` which returns `bool` `Tensor`\n      indicated fitting procedure has converged. (See inner function\n      specification for argument signature.)\n      Default value: `1e-5`.", "code": "def convergence_criteria_small_relative_norm_weights_change(\n    tolerance=1e-5,\n    norm_order=2):\n  \"\"\"\n  \"\"\"\n  def convergence_criteria_fn(\n      is_converged_previous,  # pylint: disable=unused-argument\n      iter_,\n      model_coefficients_previous,\n      predicted_linear_response_previous,  # pylint: disable=unused-argument\n      model_coefficients_next,\n      predicted_linear_response_next,  # pylint: disable=unused-argument\n      response,  # pylint: disable=unused-argument\n      model,  # pylint: disable=unused-argument\n      dispersion):  # pylint: disable=unused-argument\n    \"\"\"Returns `bool` `Tensor` indicating if fitting procedure has converged.\n\n    Args:\n      is_converged_previous: \"old\" convergence results.\n      iter_: Iteration number.\n      model_coefficients_previous: \"old\" `model_coefficients`.\n      predicted_linear_response_previous: \"old\" `predicted_linear_response`.\n      model_coefficients_next: \"new\" `model_coefficients`.\n      predicted_linear_response_next: \"new: `predicted_linear_response`.\n      response: (Batch of) vector-shaped `Tensor` where each element represents\n        a sample's observed response (to the corresponding row of features).\n        Must have same `dtype` as `model_matrix`.\n      model: `tfp.glm.ExponentialFamily`-like instance used to construct the\n        negative log-likelihood loss, gradient, and expected Hessian (i.e., the\n        Fisher information matrix).\n      dispersion: `Tensor` representing `response` dispersion, i.e., as in:\n        `p(y|theta) := exp((y theta - A(theta)) / dispersion)`. Must broadcast\n        with rows of `model_matrix`.\n        Default value: `None` (i.e., \"no dispersion\").\n\n    Returns:\n      is_converged: `bool` `Tensor`.\n    \"\"\"\n    relative_euclidean_norm = (\n        tf.norm(\n            tensor=model_coefficients_previous - model_coefficients_next,\n            ord=norm_order,\n            axis=-1) /\n        (1. +\n         tf.norm(tensor=model_coefficients_previous, ord=norm_order, axis=-1)))\n    return (iter_ > 0) & tf.reduce_all(\n        input_tensor=relative_euclidean_norm < tolerance)\n\n  return convergence_criteria_fn", "dist_before": 0.11798228323459625, "dist_after": 0.12568029761314392, "dist_change": 0.0076980143785476685}
{"pair_id": 2232, "source": "CSN Test", "query": "Exchange messages between basic pipelines and the Yandex.Dialogs service.\n    If the pipeline returns multiple values, only the first one is forwarded to Yandex.", "code": "def interact_alice(agent: Agent):\n    \"\"\"\n    \n    \"\"\"\n    data = request.get_json()\n    text = data['request'].get('command', '').strip()\n    payload = data['request'].get('payload')\n\n    session_id = data['session']['session_id']\n    user_id = data['session']['user_id']\n    message_id = data['session']['message_id']\n\n    dialog_id = DialogID(user_id, session_id)\n\n    response = {\n        'response': {\n            'end_session': True,\n            'text': ''\n        },\n        \"session\": {\n            'session_id': session_id,\n            'message_id': message_id,\n            'user_id': user_id\n        },\n        'version': '1.0'\n    }\n\n    agent_response: Union[str, RichMessage] = agent([payload or text], [dialog_id])[0]\n    if isinstance(agent_response, RichMessage):\n        response['response']['text'] = '\\n'.join([j['content']\n                                                  for j in agent_response.json()\n                                                  if j['type'] == 'plain_text'])\n    else:\n        response['response']['text'] = str(agent_response)\n\n    return jsonify(response), 200", "dist_before": 0.061679475009441376, "dist_after": 0.06160340830683708, "dist_change": -7.606670260429382e-05}
{"pair_id": 886, "source": "CSN Test", "query": "Takes a value from MSSQL, and converts it to a value that's safe for\n        JSON/Google Cloud Storage/BigQuery.", "code": "def convert_types(cls, value):\n        \"\"\"\n        \n        \"\"\"\n        if isinstance(value, decimal.Decimal):\n            return float(value)\n        else:\n            return value", "dist_before": 0.017325129359960556, "dist_after": 0.12089258432388306, "dist_change": 0.1035674512386322}
{"pair_id": 562, "source": "CSN Test", "query": "Retrieve database hook. This is the actual Postgres or MySQL database hook\n        that uses proxy or connects directly to the Google Cloud SQL database.", "code": "def get_database_hook(self):\n        \"\"\"\n        \n        \"\"\"\n        if self.database_type == 'postgres':\n            self.db_hook = PostgresHook(postgres_conn_id=self.db_conn_id,\n                                        schema=self.database)\n        else:\n            self.db_hook = MySqlHook(mysql_conn_id=self.db_conn_id,\n                                     schema=self.database)\n        return self.db_hook", "dist_before": 0.05672850459814072, "dist_after": 0.05934702977538109, "dist_change": 0.0026185251772403717}
{"pair_id": 818, "source": "CSN Test", "query": "Returns whether or not all the conditions are met for this task instance to be run\n        given the context for the dependencies (e.g. a task instance being force run from\n        the UI will ignore some dependencies).\n\n        :param dep_context: The execution context that determines the dependencies that\n            should be evaluated.\n        :type dep_context: DepContext\n        :param session: database session\n        :type session: sqlalchemy.orm.session.Session\n        :param verbose: whether log details on failed dependencies on\n            info or debug log level\n        :type verbose: bool", "code": "def are_dependencies_met(\n            self,\n            dep_context=None,\n            session=None,\n            verbose=False):\n        \"\"\"\n        \n        \"\"\"\n        dep_context = dep_context or DepContext()\n        failed = False\n        verbose_aware_logger = self.log.info if verbose else self.log.debug\n        for dep_status in self.get_failed_dep_statuses(\n                dep_context=dep_context,\n                session=session):\n            failed = True\n\n            verbose_aware_logger(\n                \"Dependencies not met for %s, dependency '%s' FAILED: %s\",\n                self, dep_status.dep_name, dep_status.reason\n            )\n\n        if failed:\n            return False\n\n        verbose_aware_logger(\"Dependencies all met for %s\", self)\n        return True", "dist_before": 0.054368987679481506, "dist_after": 0.07146566361188889, "dist_change": 0.01709667593240738}
{"pair_id": 3772, "source": "CoSQA", "query": "python argparse add subparser", "code": "def addSubparser(subparsers, subcommand, description):\n    \"\"\"\n    Add a subparser with subcommand to the subparsers object\n    \"\"\"\n    parser = subparsers.add_parser(\n        subcommand, description=description, help=description)\n    return parser", "dist_before": 0.3005877435207367, "dist_after": 0.18008169531822205, "dist_change": -0.12050604820251465}
{"pair_id": 4186, "source": "CoSQA", "query": "python check if any variable in list is type", "code": "def is_list_of(x, typ):\n    return isinstance(x, list) and all(isinstance(i, typ) for i in x)", "dist_before": 0.3593425750732422, "dist_after": 0.24032847583293915, "dist_change": -0.11901409924030304}
{"pair_id": 3463, "source": "CoSQA", "query": "python index of last string", "code": "def get_last(a):\n  for i, e in enumerate(reversed(a)):\n    if e is not None:\n      return len(a) - i - 1\n  return -1", "dist_before": 0.4998018741607666, "dist_after": 0.38669049739837646, "dist_change": -0.11311137676239014}
{"pair_id": 3370, "source": "CoSQA", "query": "python check modified time of file", "code": "def file_modified_time(file_name) -> pd.Timestamp:\n    \"\"\"\n    File modified time in python\n\n    Args:\n        file_name: file name\n\n    Returns:\n        pd.Timestamp\n    \"\"\"\n    return pd.to_datetime(time.ctime(os.path.getmtime(filename=file_name)))", "dist_before": 0.36549112200737, "dist_after": 0.3291560411453247, "dist_change": -0.03633508086204529}
{"pair_id": 3805, "source": "CoSQA", "query": "python checking equality between objects", "code": "def __eq__(self, other):\n        return self.domain == other.domain and self.python_version == other.python_version", "dist_before": 0.27842044830322266, "dist_after": 0.3010621964931488, "dist_change": 0.022641748189926147}
